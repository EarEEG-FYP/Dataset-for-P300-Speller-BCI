{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n"
      ],
      "metadata": {
        "id": "xJw2lPAfRg9j"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet = torchvision.models.alexnet(pretrained=True)"
      ],
      "metadata": {
        "id": "PsxVgWJjRkzy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU6tLV0Wjtsn",
        "outputId": "1afb8157-96bb-4eac-d3bb-b20be9e03247"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in alexnet.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "-T2QLE2USL4Z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet.classifier[6] = nn.Linear(4096, 2)\n",
        "alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim = 1))\n",
        "alexnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwtkNd8gkgw6",
        "outputId": "6462768c-6fd5-41bd-d24f-e5c70122f9ed"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "    (7): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(alexnet, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYtHH7LSoMS0",
        "outputId": "2b15947a-2e69-4e98-88f9-7036c9d40eb9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 55, 55]          23,296\n",
            "              ReLU-2           [-1, 64, 55, 55]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                    [-1, 2]           8,194\n",
            "       LogSoftmax-22                    [-1, 2]               0\n",
            "================================================================\n",
            "Total params: 57,012,034\n",
            "Trainable params: 8,194\n",
            "Non-trainable params: 57,003,840\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 8.37\n",
            "Params size (MB): 217.48\n",
            "Estimated Total Size (MB): 226.43\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(alexnet.parameters())\n",
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpMeG2vMqDO-",
        "outputId": "197a5b6a-bf67-4b06-c837-f13c62ea515d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMVqAnnGtVTQ",
        "outputId": "c9cee895-98b3-4ce1-857d-9b7e8f4f71e3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_and_labels(folder_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".png\"):\n",
        "\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image = Image.open(image_path)\n",
        "            image = image.convert(\"RGB\")\n",
        "\n",
        "            image = image.resize((224,224))\n",
        "            image_array = np.array(image) / 255.0\n",
        "            images.append(image_array)\n",
        "\n",
        "            if (\"target\" in filename) & (\"nontarget\" not in filename):\n",
        "                labels.append(1)\n",
        "            elif \"nontarget\" in filename:\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                raise ValueError(\"Invalid filename format\")\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "BKtLyXt6qsRW"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/gdrive/MyDrive/Colab Notebooks/FYP_coding/DataSet/Scalograms/'\n",
        "X, Y = load_images_and_labels(folder_path)\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of Y:\", Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAqjBZX6tLHS",
        "outputId": "6ae62225-a526-4398-d448-418a9dc7c51a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (52, 224, 224, 3)\n",
            "Shape of Y: (52,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scwx_XWw2UvT",
        "outputId": "ef4db087-acce-4b98-8f29-09b5b34767e5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images here i used imagenet stats ??\n",
        "])\n"
      ],
      "metadata": {
        "id": "J2J0Nzitttsn"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxiC74TS0SXV",
        "outputId": "188075d1-bfad-438e-d0d2-a6f3c2ee4dc1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset\n",
        "dataset = CustomDataset(X, Y, transform=transform)\n",
        "\n",
        "# Define data loader\n",
        "batch_size = 16\n",
        "\n",
        "# Split the dataset into training and testing subsets\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "p7aGiN-6yzkM"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # Training loop\n",
        "    alexnet.train()\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = alexnet(images.float())\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation loop\n",
        "    alexnet.eval()\n",
        "    with torch.no_grad():\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        for images, labels in test_loader:\n",
        "            outputs = alexnet(images.float())\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "        accuracy = total_correct / total_samples\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyPdGBG6wUWs",
        "outputId": "2cdb5a26-f765-44af-a79d-7ab220c9a390"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Accuracy: 1.0000\n",
            "Epoch [2/10], Accuracy: 1.0000\n",
            "Epoch [3/10], Accuracy: 1.0000\n",
            "Epoch [4/10], Accuracy: 1.0000\n",
            "Epoch [5/10], Accuracy: 1.0000\n",
            "Epoch [6/10], Accuracy: 1.0000\n",
            "Epoch [7/10], Accuracy: 1.0000\n",
            "Epoch [8/10], Accuracy: 1.0000\n",
            "Epoch [9/10], Accuracy: 1.0000\n",
            "Epoch [10/10], Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}