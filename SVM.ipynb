{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuWefpCA2cOT",
        "outputId": "da636803-19e6-4c8f-c09a-f7f282bbbd65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mat73 in c:\\users\\lakshan rathnayake\\anaconda3\\lib\\site-packages (0.62)\n",
            "Requirement already satisfied: h5py in c:\\users\\lakshan rathnayake\\anaconda3\\lib\\site-packages (from mat73) (3.1.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\lakshan rathnayake\\anaconda3\\lib\\site-packages (from mat73) (1.20.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mat73"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3-sV4kwFuIr",
        "outputId": "56c11345-537f-489e-9321-d38b1cf37b4d"
      },
      "outputs": [],
      "source": [
        "import mat73\n",
        "import scipy\n",
        "import scipy.io as sio # cannot use for v7.3 mat file\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from scipy.signal import butter, filtfilt, sosfiltfilt\n",
        "\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yvlRvEOYGMEG"
      },
      "outputs": [],
      "source": [
        "# filters\n",
        "\n",
        "def butter_lowpass_filter(data, lowcut, fs, order):\n",
        "    nyq = fs/2\n",
        "    low = lowcut/nyq\n",
        "    b, a = butter(order, low, btype='low')\n",
        "    # demean before filtering\n",
        "    meandat = np.mean(data, axis=1)\n",
        "    data = data - meandat[:, np.newaxis]\n",
        "    y = filtfilt(b, a, data) # zero-phase filter # data: [ch x time]\n",
        "    return y\n",
        "\n",
        "def butter_highpass_filter(data, highcut, fs, order):\n",
        "    nyq = fs/2\n",
        "    high = highcut/nyq\n",
        "    b, a = butter(order, high, btype='high')\n",
        "    # demean before filtering\n",
        "    meandat = np.mean(data, axis=1)\n",
        "    data = data - meandat[:, np.newaxis]\n",
        "    y = filtfilt(b, a, data) # zero-phase filter # data: [ch x time]\n",
        "    return y\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
        "    nyq = fs/2\n",
        "    low = lowcut/nyq\n",
        "    high = highcut/nyq\n",
        "    sos = butter(order, [low, high], btype='band', output='sos')\n",
        "    # demean before filtering\n",
        "    meandat = np.mean(data, axis=1)\n",
        "    data = data - meandat[:, np.newaxis]\n",
        "    y = sosfiltfilt(sos, data) # zero-phase filter # data: [ch x time]\n",
        "    # specify pandlen to make the result the same as Matlab filtfilt()\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F2pDrZtzGfMU"
      },
      "outputs": [],
      "source": [
        "#Pre processing\n",
        "\n",
        "def extractEpoch3D(data, event, srate, baseline, frame, opt_keep_baseline):\n",
        "    # extract epoch from 2D data into 3D [ch x time x trial]\n",
        "    # input: event, baseline, frame\n",
        "    # extract epoch = baseline[0] to frame[2]   so the time frame is -200 to 600 ms.\n",
        "\n",
        "    # for memory pre-allocation\n",
        "    if opt_keep_baseline == True:\n",
        "        begin_tmp = int(np.floor(baseline[0]/1000*srate))\n",
        "        end_tmp = int(begin_tmp+np.floor(frame[1]-baseline[0])/1000*srate)\n",
        "    else:\n",
        "        begin_tmp = int(np.floor(frame[0]/1000*srate))\n",
        "        end_tmp = int(begin_tmp+np.floor(frame[1]-frame[0])/1000*srate)\n",
        "\n",
        "    epoch3D = np.zeros((data.shape[0], end_tmp-begin_tmp, len(event)))\n",
        "    nth_event = 0 # trial\n",
        "\n",
        "    for i in event:\n",
        "        if opt_keep_baseline == True:\n",
        "            begin_id = int(i + np.floor(baseline[0]/1000 * srate))                 # int(i + begin_tmp)\n",
        "            end_id = int(begin_id + np.floor((frame[1]-baseline[0])/1000*srate))   # int(i + end_tmp)\n",
        "        else:\n",
        "            begin_id = int(i + np.floor(frame[0]/1000 * srate))\n",
        "            end_id = int(begin_id + np.floor((frame[1]-frame[0])/1000*srate))\n",
        "\n",
        "        tmp_data = data[:, begin_id:end_id] # extract the time period\n",
        "\n",
        "        begin_base = int(np.floor(baseline[0]/1000 * srate))+i\n",
        "        end_base = int(begin_base + np.floor(np.diff(baseline)/1000 * srate)-1)\n",
        "        base = np.mean(data[:, begin_base:end_base], axis=1)\n",
        "\n",
        "        rmbase_data = tmp_data - base[:, np.newaxis]\n",
        "        epoch3D[:, :, nth_event] = rmbase_data\n",
        "        nth_event = nth_event + 1\n",
        "\n",
        "    return epoch3D\n",
        "\n",
        "def decimation_by_avg(data, factor):\n",
        "    \"\"\"Function for replacing each sequence of previous factor samples with their average\"\"\"\n",
        "    # for example, frame [0, 800]ms -> 17samples (Krusienski et al., 2006)\n",
        "    # data.shape = [ch, time, trial]\n",
        "    ratio_dsample = factor\n",
        "    n_ch, n_frame, n_trial = data.shape\n",
        "\n",
        "    print(\"n_frame\" ,n_frame)\n",
        "    decimated_frame = int(np.floor(n_frame/ratio_dsample))\n",
        "    print(\"decimated_frame \",decimated_frame)\n",
        "\n",
        "    # memory pre-allocation\n",
        "    decimated_data = np.zeros((n_ch, decimated_frame, n_trial))\n",
        "    print(\"decimated_data.shape \",decimated_data.shape)\n",
        "\n",
        "    for i in range(n_trial):\n",
        "        for j in range(decimated_frame):\n",
        "            cur_data = data[:, :, i]\n",
        "            decimated_data[:, j, i] = np.mean(cur_data[:, j*ratio_dsample:(j+1)*ratio_dsample], axis=1)\n",
        "\n",
        "    return decimated_data\n",
        "\n",
        "def detect_letter_P3speller(pred_score, word_len, label, letter_ind, markers_seq, params):\n",
        "    \"\"\"Function for detecing letter from the predicted results from unknown EEG\"\"\"\n",
        "    user_answer = np.chararray(word_len,1)\n",
        "    acc_on_repetition = np.zeros(params[\"full_repeat\"])\n",
        "    correct_on_repetition = np.zeros(params[\"full_repeat\"])\n",
        "    for n_repeat in range(params[\"full_repeat\"]):\n",
        "        for n_letter in range(word_len):\n",
        "            # begin and end trial for a single letter session\n",
        "            begin_trial = len(params[\"seq_code\"]) * params[\"full_repeat\"] * (n_letter)\n",
        "            end_trial = begin_trial + (n_repeat+1) * len(params[\"seq_code\"])\n",
        "\n",
        "            unknown_speller_code = np.zeros(len(params[\"seq_code\"]))\n",
        "            for j in range(begin_trial, end_trial):\n",
        "                # predict and add lda score\n",
        "                unknown_speller_code[int(markers_seq[letter_ind[j]])-1] = unknown_speller_code[int(markers_seq[letter_ind[j]])-1] + pred_score[j]\n",
        "\n",
        "            row = np.argmax(unknown_speller_code[0:6])\n",
        "            col = np.argmax(unknown_speller_code[6:12])\n",
        "            user_answer[n_letter] = params['spellermatrix'][row*6+col]\n",
        "        user_answer_string = user_answer.tobytes().decode()\n",
        "\n",
        "        correct_on_repetition[n_repeat] = len([i for i, j in zip(user_answer_string, label) if i == j])\n",
        "        acc_on_repetition[n_repeat] = correct_on_repetition[n_repeat] / len(label)\n",
        "\n",
        "    out = {\"text_result\": user_answer_string, \"acc_on_repetition\": acc_on_repetition, \"correct_on_repetition\": correct_on_repetition}\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XfSs-xefHNYL"
      },
      "outputs": [],
      "source": [
        "# pre-defined parameters\n",
        "baseline = [-200, 0] # in ms\n",
        "frame = [0, 600] # in ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vxz9xIzJoBz"
      },
      "outputs": [],
      "source": [
        "EEG = mat73.loadmat(\"/content/gdrive/MyDrive/Colab Notebooks/FYP_coding/DataSet/s01.mat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0JmnVd0HcvL"
      },
      "source": [
        "# **Code for prediction letters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5QWS8dzQJiD",
        "outputId": "cf51074c-55be-41fd-b4b4-e82e99a8eff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_frame 409\n",
            "decimated_frame  17\n",
            "decimated_data.shape  (32, 17, 4560)\n",
            "n_frame 409\n",
            "decimated_frame  17\n",
            "decimated_data.shape  (32, 17, 22800)\n",
            "(27360, 544) (27360, 1)\n"
          ]
        }
      ],
      "source": [
        "#Load Dataset\n",
        "\n",
        "EEG_data = []\n",
        "# path = \"/content/gdrive/MyDrive/Colab Notebooks/FYP_coding/DataSet/\"\n",
        "path = \"./DataSet/\"\n",
        "for subject in range(1,5):\n",
        "    eeg = mat73.loadmat(path+'s{:02d}.mat'.format(int(subject)))\n",
        "    EEG_data += eeg['train'] + eeg['test']\n",
        "\n",
        "#Pre-processing for training EEG\n",
        "\n",
        "for n_calib in range(len(EEG_data)):\n",
        "    # print(n_calib)\n",
        "    cur_eeg = EEG_data[n_calib]\n",
        "\n",
        "    data = np.asarray(cur_eeg['data'])\n",
        "    srate = cur_eeg['srate']\n",
        "    data = butter_bandpass_filter(data, 0.5, 10, srate, 4)\n",
        "    markers = cur_eeg['markers_target']\n",
        "\n",
        "    targetID = np.where(markers==1)[0]\n",
        "    nontargetID = np.where(markers==2)[0]\n",
        "\n",
        "    tmp_targetEEG = extractEpoch3D(data, targetID, srate, baseline, frame, True)\n",
        "    tmp_nontargetEEG = extractEpoch3D(data, nontargetID, srate, baseline, frame, True)\n",
        "    if n_calib == 0:\n",
        "        targetEEG = tmp_targetEEG\n",
        "        nontargetEEG = tmp_nontargetEEG\n",
        "    else:\n",
        "        targetEEG = np.dstack((targetEEG, tmp_targetEEG)) # np.dstack is a function that stacks arrays in sequence along the third axis (depth). Given a sequence of arrays with the same shape along the first two dimensions, np.dstack concatenates them along the third axis. The function name \"dstack\" stands for \"depth stack.\"\n",
        "        nontargetEEG = np.dstack((nontargetEEG, tmp_nontargetEEG))\n",
        "\n",
        "\n",
        "# Averaging in time axis\n",
        "down_target = decimation_by_avg(targetEEG, 24)\n",
        "down_nontarget = decimation_by_avg(nontargetEEG, 24)\n",
        "\n",
        "ch_target, frame_target, trial_target = down_target.shape\n",
        "ch_nontarget, frame_nontarget, trial_nontarget = down_nontarget.shape\n",
        "\n",
        "# ch x time x trial -> (ch* time) x trial -> trial x (ch*time)\n",
        "feat_target = np.reshape(down_target, (ch_target*frame_target, trial_target)).transpose()\n",
        "feat_nontarget = np.reshape(down_nontarget, (ch_nontarget*frame_nontarget, trial_nontarget)).transpose()\n",
        "\n",
        "# labels - (+1) for target and (-1) for nontarget\n",
        "y_target = np.ones((feat_target.shape[0],1))\n",
        "y_nontarget = -np.ones((feat_nontarget.shape[0],1))\n",
        "\n",
        "X_ = np.vstack((feat_target, feat_nontarget))\n",
        "y_ = np.vstack((y_target, y_nontarget))\n",
        "\n",
        "print(X_.shape, y_.shape)\n",
        "\n",
        "# shuffle target and nontarget indices\n",
        "np.random.seed(101)\n",
        "idx_train = np.arange(X_.shape[0])\n",
        "np.random.shuffle(idx_train)\n",
        "X_ = X_[idx_train, :]\n",
        "y_ = y_[idx_train, :]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs8LnCWYjvtP",
        "outputId": "b4cc7b73-890a-4a5e-aef2-a42c72d9be00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target EEG shape (32, 409, 4560)\n",
            "Nontarget EEG shape (32, 409, 22800)\n",
            "down_target.shape  (32, 17, 4560)\n",
            "down_nontarget.shape  (32, 17, 22800)\n",
            "Target feature vector shape (4560, 544)\n",
            "Nontarget feature vector shape (22800, 544)\n",
            "X_ vector shape (27360, 544)\n",
            "y_ vector shape (27360, 1)\n",
            "X_train vector shape (21888, 544)\n",
            "y_train vector shape (21888, 1)\n",
            "X_test vector shape (5472, 544)\n",
            "y_test vector shape (5472, 1)\n"
          ]
        }
      ],
      "source": [
        "# data dimension for\n",
        "print('Target EEG shape', targetEEG.shape) # ch x time x trial                  In one calibration run has 150 target and 750 nontarget events. There are 2 calibration runs, so after stacking shape is Target EEG shape (32, 409, 300),Nontarget EEG shape (32, 409, 1500)\n",
        "print('Nontarget EEG shape', nontargetEEG.shape) # ch x time x trial\n",
        "\n",
        "print(\"down_target.shape \", down_target.shape)\n",
        "print(\"down_nontarget.shape \", down_nontarget.shape)\n",
        "\n",
        "print('Target feature vector shape', feat_target.shape)\n",
        "print('Nontarget feature vector shape', feat_nontarget.shape)\n",
        "\n",
        "print('X_ vector shape', X_.shape)\n",
        "print('y_ vector shape', y_.shape)\n",
        "\n",
        "print('X_train vector shape', X_train.shape)\n",
        "print('y_train vector shape', y_train.shape)\n",
        "\n",
        "print('X_test vector shape', X_test.shape)\n",
        "print('y_test vector shape', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9RO0c4l6fcI",
        "outputId": "0aec4c25-34a2-4d34-8c29-66ce321e972d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\lakshan rathnayake\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Create and train the SVM model\n",
        "svm_model = SVC(kernel='linear', C=1.0)\n",
        "svm_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHTTpy3G3u2G"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_report_str = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report_str)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
