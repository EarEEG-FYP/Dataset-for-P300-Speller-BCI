{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3-sV4kwFuIr",
        "outputId": "a568f8e6-fcd9-4c34-ccf2-3086a3f77619"
      },
      "outputs": [],
      "source": [
        "import mat73\n",
        "import scipy\n",
        "import scipy.io as sio # cannot use for v7.3 mat file\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from scipy.signal import butter, filtfilt, sosfiltfilt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Filters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yvlRvEOYGMEG"
      },
      "outputs": [],
      "source": [
        "def butter_lowpass_filter(data, lowcut, fs, order):\n",
        "    nyq = fs/2\n",
        "    low = lowcut/nyq\n",
        "    b, a = butter(order, low, btype='low')\n",
        "    # demean before filtering\n",
        "    meandat = np.mean(data, axis=1)\n",
        "    data = data - meandat[:, np.newaxis]\n",
        "    y = filtfilt(b, a, data) # zero-phase filter # data: [ch x time]\n",
        "    return y\n",
        "\n",
        "def butter_highpass_filter(data, highcut, fs, order):\n",
        "    nyq = fs/2\n",
        "    high = highcut/nyq\n",
        "    b, a = butter(order, high, btype='high')\n",
        "    # demean before filtering\n",
        "    meandat = np.mean(data, axis=1)\n",
        "    data = data - meandat[:, np.newaxis]\n",
        "    y = filtfilt(b, a, data) # zero-phase filter # data: [ch x time]\n",
        "    return y\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
        "    nyq = fs/2\n",
        "    low = lowcut/nyq\n",
        "    high = highcut/nyq\n",
        "    sos = butter(order, [low, high], btype='band', output='sos')\n",
        "    # demean before filtering\n",
        "    meandat = np.mean(data, axis=1)\n",
        "    data = data - meandat[:, np.newaxis]\n",
        "    y = sosfiltfilt(sos, data) # zero-phase filter # data: [ch x time]\n",
        "    # specify pandlen to make the result the same as Matlab filtfilt()\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F2pDrZtzGfMU"
      },
      "outputs": [],
      "source": [
        "def extractEpoch3D(data, event, srate, baseline, frame, opt_keep_baseline):\n",
        "    # extract epoch from 2D data into 3D [ch x time x trial]\n",
        "    # input: event, baseline, frame\n",
        "    # extract epoch = baseline[0] to frame[2]   so the time frame is -200 to 600 ms.\n",
        "\n",
        "    # for memory pre-allocation\n",
        "    if opt_keep_baseline == True:\n",
        "        begin_tmp = int(np.floor(baseline[0]/1000*srate))\n",
        "        end_tmp = int(begin_tmp+np.floor(frame[1]-baseline[0])/1000*srate)\n",
        "    else:\n",
        "        begin_tmp = int(np.floor(frame[0]/1000*srate))\n",
        "        end_tmp = int(begin_tmp+np.floor(frame[1]-frame[0])/1000*srate)\n",
        "\n",
        "    epoch3D = np.zeros((data.shape[0], end_tmp-begin_tmp, len(event)))\n",
        "    nth_event = 0 # trial\n",
        "\n",
        "    for i in event:\n",
        "        if opt_keep_baseline == True:\n",
        "            begin_id = int(i + np.floor(baseline[0]/1000 * srate))                 # int(i + begin_tmp)\n",
        "            end_id = int(begin_id + np.floor((frame[1]-baseline[0])/1000*srate))   # int(i + end_tmp)\n",
        "        else:\n",
        "            begin_id = int(i + np.floor(frame[0]/1000 * srate))\n",
        "            end_id = int(begin_id + np.floor((frame[1]-frame[0])/1000*srate))\n",
        "\n",
        "        tmp_data = data[:, begin_id:end_id] # extract the time period\n",
        "\n",
        "        begin_base = int(np.floor(baseline[0]/1000 * srate))+i\n",
        "        end_base = int(begin_base + np.floor(np.diff(baseline)/1000 * srate)-1)\n",
        "        base = np.mean(data[:, begin_base:end_base], axis=1)\n",
        "\n",
        "        rmbase_data = tmp_data - base[:, np.newaxis]\n",
        "        epoch3D[:, :, nth_event] = rmbase_data\n",
        "        nth_event = nth_event + 1\n",
        "\n",
        "    return epoch3D\n",
        "\n",
        "def decimation_by_avg(data, factor):\n",
        "    \"\"\"Function for replacing each sequence of previous factor samples with their average\"\"\"\n",
        "    # for example, frame [0, 800]ms -> 17samples (Krusienski et al., 2006)\n",
        "    # data.shape = [ch, time, trial]\n",
        "    ratio_dsample = factor\n",
        "    n_ch, n_frame, n_trial = data.shape\n",
        "\n",
        "    print(\"n_frame\" ,n_frame)\n",
        "    decimated_frame = int(np.floor(n_frame/ratio_dsample))\n",
        "    print(\"decimated_frame \",decimated_frame)\n",
        "\n",
        "    # memory pre-allocation\n",
        "    decimated_data = np.zeros((n_ch, decimated_frame, n_trial))\n",
        "    print(\"decimated_data.shape \",decimated_data.shape)\n",
        "\n",
        "    for i in range(n_trial):\n",
        "        for j in range(decimated_frame):\n",
        "            cur_data = data[:, :, i]\n",
        "            decimated_data[:, j, i] = np.mean(cur_data[:, j*ratio_dsample:(j+1)*ratio_dsample], axis=1)\n",
        "\n",
        "    return decimated_data\n",
        "    \"\"\"Function for detecing letter from the predicted results from unknown EEG\"\"\"\n",
        "    user_answer = np.chararray(word_len,1)\n",
        "    acc_on_repetition = np.zeros(params[\"full_repeat\"])\n",
        "    correct_on_repetition = np.zeros(params[\"full_repeat\"])\n",
        "    for n_repeat in range(params[\"full_repeat\"]):\n",
        "        for n_letter in range(word_len):\n",
        "            # begin and end trial for a single letter session\n",
        "            begin_trial = len(params[\"seq_code\"]) * params[\"full_repeat\"] * (n_letter)\n",
        "            end_trial = begin_trial + (n_repeat+1) * len(params[\"seq_code\"])\n",
        "\n",
        "            unknown_speller_code = np.zeros(len(params[\"seq_code\"]))\n",
        "            for j in range(begin_trial, end_trial):\n",
        "                # predict and add lda score\n",
        "                unknown_speller_code[int(markers_seq[letter_ind[j]])-1] = unknown_speller_code[int(markers_seq[letter_ind[j]])-1] + pred_score[j]\n",
        "\n",
        "            row = np.argmax(unknown_speller_code[0:6])\n",
        "            col = np.argmax(unknown_speller_code[6:12])\n",
        "            user_answer[n_letter] = params['spellermatrix'][row*6+col]\n",
        "        user_answer_string = user_answer.tobytes().decode()\n",
        "\n",
        "        correct_on_repetition[n_repeat] = len([i for i, j in zip(user_answer_string, label) if i == j])\n",
        "        acc_on_repetition[n_repeat] = correct_on_repetition[n_repeat] / len(label)\n",
        "\n",
        "    out = {\"text_result\": user_answer_string, \"acc_on_repetition\": acc_on_repetition, \"correct_on_repetition\": correct_on_repetition}\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XfSs-xefHNYL"
      },
      "outputs": [],
      "source": [
        "# pre-defined parameters\n",
        "baseline = [-200, 0] # in ms\n",
        "frame = [0, 600] # in ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0JmnVd0HcvL"
      },
      "source": [
        "## **Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5QWS8dzQJiD",
        "outputId": "0892c619-6d16-450e-faad-b427043ab31b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_frame 409\n",
            "decimated_frame  17\n",
            "decimated_data.shape  (32, 17, 35)\n",
            "n_frame 409\n",
            "decimated_frame  17\n",
            "decimated_data.shape  (32, 17, 178)\n",
            "(213, 544) (213, 1)\n"
          ]
        }
      ],
      "source": [
        "#Load Dataset\n",
        "\n",
        "EEG_data = []\n",
        "path = \"/Volumes/Yohan's_T7/FYP/Datasets/P300 Speller/\"\n",
        "for subject in range(1,5):\n",
        "  try:\n",
        "    eeg = mat73.loadmat(path+'s{:02d}.mat'.format(int(subject)))\n",
        "    EEG_data += eeg['train'] + eeg['test']\n",
        "  except Exception as e:\n",
        "    print(subject, \" is not a MATLAB 7.3 file.\")\n",
        "#Pre-processing for training EEG\n",
        "\n",
        "for n_calib in range(len(EEG_data)):\n",
        "    # print(n_calib)\n",
        "    cur_eeg = EEG_data[n_calib]\n",
        "\n",
        "    data = np.asarray(cur_eeg['data'])\n",
        "    srate = cur_eeg['srate']\n",
        "    data = butter_bandpass_filter(data, 0.5, 10, srate, 4)\n",
        "    markers = cur_eeg['markers_target']\n",
        "\n",
        "    targetID = np.where(markers==1)[0]\n",
        "    nontargetID = np.where(markers==2)[0]\n",
        "\n",
        "    tmp_targetEEG = extractEpoch3D(data, targetID, srate, baseline, frame, True)\n",
        "    tmp_nontargetEEG = extractEpoch3D(data, nontargetID, srate, baseline, frame, True)\n",
        "    if n_calib == 0:\n",
        "        targetEEG = tmp_targetEEG\n",
        "        nontargetEEG = tmp_nontargetEEG\n",
        "    else:\n",
        "        targetEEG = np.dstack((targetEEG, tmp_targetEEG)) # np.dstack is a function that stacks arrays in sequence along the third axis (depth). Given a sequence of arrays with the same shape along the first two dimensions, np.dstack concatenates them along the third axis. The function name \"dstack\" stands for \"depth stack.\"\n",
        "        nontargetEEG = np.dstack((nontargetEEG, tmp_nontargetEEG))\n",
        "\n",
        "# Ensemble accross trials\n",
        "num_of_target_signals = targetEEG.shape[2] // 128\n",
        "num_of_nontarget_signals = nontargetEEG.shape[2] // 128\n",
        "avg_target = np.zeros((targetEEG.shape[0], targetEEG.shape[1], num_of_target_signals))\n",
        "avg_nontarget = np.zeros((nontargetEEG.shape[0], nontargetEEG.shape[1], num_of_nontarget_signals))\n",
        "\n",
        "for i in range(num_of_target_signals):\n",
        "  if i != num_of_target_signals-1:\n",
        "    avg_target[:,:,i] = np.mean(targetEEG[:, :, i:i+128 ], axis=2)\n",
        "  else:\n",
        "    avg_target[:,:,i] = np.mean(targetEEG[:, :, i: ], axis=2)\n",
        "\n",
        "for i in range(num_of_nontarget_signals):\n",
        "  if i != num_of_nontarget_signals-1:\n",
        "    avg_nontarget[:,:,i] = np.mean(nontargetEEG[:, :, i:i+128 ], axis=2)\n",
        "  else:\n",
        "    avg_nontarget[:,:,i] = np.mean(nontargetEEG[:, :, i: ], axis=2)\n",
        "\n",
        "\n",
        "# Averaging in time axis\n",
        "down_target = decimation_by_avg(avg_target, 24)\n",
        "down_nontarget = decimation_by_avg(avg_nontarget, 24)\n",
        "\n",
        "ch_target, frame_target, trial_target = down_target.shape\n",
        "ch_nontarget, frame_nontarget, trial_nontarget = down_nontarget.shape\n",
        "\n",
        "# ch x time x trial -> (ch* time) x trial -> trial x (ch*time)\n",
        "feat_target = np.reshape(down_target, (ch_target*frame_target, trial_target)).transpose()\n",
        "feat_nontarget = np.reshape(down_nontarget, (ch_nontarget*frame_nontarget, trial_nontarget)).transpose()\n",
        "\n",
        "# labels - (+1) for target and (-1) for nontarget\n",
        "y_target = np.ones((feat_target.shape[0],1))\n",
        "y_nontarget = -np.ones((feat_nontarget.shape[0],1))\n",
        "\n",
        "X_ = np.vstack((feat_target, feat_nontarget))\n",
        "y_ = np.vstack((y_target, y_nontarget))\n",
        "\n",
        "print(X_.shape, y_.shape)\n",
        "\n",
        "# shuffle target and nontarget indices\n",
        "np.random.seed(101)\n",
        "idx_train = np.arange(X_.shape[0])\n",
        "np.random.shuffle(idx_train)\n",
        "X_ = X_[idx_train, :]\n",
        "y_ = y_[idx_train, :]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Standardize the features\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs8LnCWYjvtP",
        "outputId": "9f07dabb-8007-4818-c4fc-cb6d0a1c1c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target EEG shape (32, 409, 4560)\n",
            "Nontarget EEG shape (32, 409, 22800)\n",
            "down_target.shape  (32, 17, 35)\n",
            "down_nontarget.shape  (32, 17, 178)\n",
            "Target feature vector shape (35, 544)\n",
            "Nontarget feature vector shape (178, 544)\n",
            "X_ vector shape (213, 544)\n",
            "y_ vector shape (213, 1)\n",
            "X_train vector shape (170, 544)\n",
            "y_train vector shape (170, 1)\n",
            "X_test vector shape (43, 544)\n",
            "y_test vector shape (43, 1)\n"
          ]
        }
      ],
      "source": [
        "# data dimension for\n",
        "print('Target EEG shape', targetEEG.shape) # ch x time x trial                  In one calibration run has 150 target and 750 nontarget events. There are 2 calibration runs, so after stacking shape is Target EEG shape (32, 409, 300),Nontarget EEG shape (32, 409, 1500)\n",
        "print('Nontarget EEG shape', nontargetEEG.shape) # ch x time x trial\n",
        "\n",
        "print(\"down_target.shape \", down_target.shape)\n",
        "print(\"down_nontarget.shape \", down_nontarget.shape)\n",
        "\n",
        "print('Target feature vector shape', feat_target.shape)\n",
        "print('Nontarget feature vector shape', feat_nontarget.shape)\n",
        "\n",
        "print('X_ vector shape', X_.shape)\n",
        "print('y_ vector shape', y_.shape)\n",
        "\n",
        "print('X_train vector shape', X_train.shape)\n",
        "print('y_train vector shape', y_train.shape)\n",
        "\n",
        "print('X_test vector shape', X_test.shape)\n",
        "print('y_test vector shape', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.29379409 -0.46046414  0.17702947 ... -0.22595577 -0.28246523\n",
            "   0.14508754]\n",
            " [ 0.05243807  0.09942939  0.36122022 ...  0.58981844  0.11231765\n",
            "  -0.20727136]\n",
            " [-0.27234461 -0.60606505  0.12296636 ... -0.10772195 -0.36920578\n",
            "  -0.03473265]\n",
            " ...\n",
            " [-0.19252623 -0.42439356  0.08932038 ... -0.4404285  -0.35448375\n",
            "   0.15390133]\n",
            " [-0.22650168 -0.29740222  0.28667153 ... -0.32373499 -0.42298247\n",
            "   0.23119115]\n",
            " [ 0.04618246  0.09411089  0.25534186 ...  0.64634033  0.20402486\n",
            "  -0.08258255]]\n"
          ]
        }
      ],
      "source": [
        "print(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.20684385 -0.47785116 -0.00809379 ... -0.06948468 -0.11207144\n",
            "   0.0372326 ]\n",
            " [-0.35431119 -0.49033321  0.22850825 ... -0.38725251 -0.36101458\n",
            "   0.12241814]\n",
            " [-0.31781763 -0.47558028  0.19035954 ... -0.42751295 -0.37661649\n",
            "   0.13451004]\n",
            " ...\n",
            " [-0.2022988  -0.53330245  0.15601762 ... -0.29218985 -0.25550721\n",
            "   0.24505412]\n",
            " [-0.15325481 -0.55337675  0.0858214  ... -0.44893691 -0.38430883\n",
            "   0.05123369]\n",
            " [-0.12243818 -0.16697706 -0.00145243 ... -0.17165864 -0.32514091\n",
            "  -0.00407937]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.]\n",
            " [ 1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [ 1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [ 1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [ 1.]\n",
            " [-1.]\n",
            " [ 1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [ 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Saving Data Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(X_test)\n",
        "csv_file =  'X_test.csv'\n",
        "df.to_csv(csv_file, index=False)\n",
        "\n",
        "df = pd.DataFrame(X_train)\n",
        "csv_file =  'X_train.csv'\n",
        "df.to_csv(csv_file, index=False)\n",
        "\n",
        "df = pd.DataFrame(y_test)\n",
        "csv_file =  'Y_test.csv'\n",
        "df.to_csv(csv_file, index=False)\n",
        "\n",
        "df = pd.DataFrame(y_train)\n",
        "csv_file =  'Y_train.csv'\n",
        "df.to_csv(csv_file, index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9 (pytorch)",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
